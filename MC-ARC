# -*- coding: utf-8 -*-
from collections import defaultdict, OrderedDict
from structures.file import File
from policy.policy import Policy
import numpy as np
import datetime
import os


class mc_arc(Policy):
    """
    MC-ARC is a multi-criteria, file-level eviction policy
    that combines frequency and recency of access with file
    lifetime and fairness considerations.
    """

    def __init__(self, cache_size, users, alpha, ssd_tier, hdd_tier, log_file_path, total_io_count):
        """
        Initialize the MC-ARC caching policy instance.

        :param cache_size: The size of the cache (in number of blocks).
        :param users: A dictionary of user objects.
        :param alpha: A parameter used by the policy for adaptation.
        :param ssd_tier: The SSD tier, managing its own read/write operations.
        :param hdd_tier: The HDD tier, managing its own read/write operations.
        :param log_file_path: Path to the log file where user times are logged.
        :param total_io_count: Total number of IO operations.
        """

        # Call parent constructor
        super().__init__(cache_size, alpha, ssd_tier, hdd_tier)

        # Indicates if we are dealing with a new file
        self.new_file = False

        # p: adaptation parameter that changes with the policy
        self.p = 0

        # Number of prefetch times (not used in detail here)
        self.prefetch_times = 0

        # Counter for IO operations
        self.io_counter = 0

        # Total IO operations that will be handled by the system
        self.total_io_operations = total_io_count

        # Dictionary of users
        self.users = users

        # c: the cache size (in blocks)
        self.c = cache_size

        # alpha: adaptation parameter from the policy
        self.alpha = alpha

        # Block size = 4 KB
        self.block_size = 4 * 1024

        # SSD and HDD tiers
        self.ssd_tier = ssd_tier
        self.hdd_tier = hdd_tier

        # Path to the log file for user time logging
        self.log_file_path = log_file_path

        # Main cache structures: T1, T2 for actual data; B1, B2 for ghost entries
        self.t1 = OrderedDict()
        self.t2 = OrderedDict()
        self.b1 = OrderedDict()
        self.b2 = OrderedDict()

        # Accumulator for output messages (if needed)
        self.output_accumulator = ""

        # Count of blocks read from HDD
        self.nbr_of_blocks_hdd_reads = 0

        # Hits and Misses
        self.hits = 0
        self.misses = 0

        # Eviction misses (file was evicted from SSD) and cold misses (file never in SSD before)
        self.eviction_misses = 0
        self.cold_misses = 0

        # Track user requests and throughput metrics
        self.user_requests = defaultdict(int)
        self.user_request_sizes = defaultdict(int)
        self.user_total_time = defaultdict(float)

        # Counters for read/write times and total time
        self.read_times = 0
        self.write_times = 0
        self.total_time = 0

        # Eviction metrics
        self.evicted_blocks_count = 0
        self.evicted_file_count = 0
        self.file2blocks = defaultdict(set)
        self.file2tier = defaultdict(int)
        self.migration_times = 0
        self.adapte_B1 = 0
        self.adapte_B2 = 0

        # Time spent accessing SSD and HDD
        self.ssd_time = 0
        self.hdd_time = 0

        # Track which files are currently in SSD and which have been evicted from SSD
        self.files_in_ssd = set()
        self.evicted_files_SSD = set()

        # Path to eviction log file
        self.eviction_log_file = 'app/scen1/20/wsm/eviction_log.txt'

        # Track all evicted files
        self.evicted_files = set()

        # Size of the "burst buffer" = 256 KB
        self.burst_buffer_size = 256 * 1024

    def remove_all(self, file: File):
        """
        Remove all blocks of the given file from both T1 and T2,
        and place them in the corresponding ghost lists B1 or B2.
        Resets the file's tier membership to 0 (not in SSD).

        :param file: The File object to remove from SSD (T1 or T2).
        """
        # Collect blocks from T1 and T2 that belong to this file
        blocks_t1 = [block for block in self.t1 if block[0] == file]
        blocks_t2 = [block for block in self.t2 if block[0] == file]

        # Remove those blocks from T1, place them in B1
        for block in blocks_t1:
            del self.t1[block]
            self.b1[block] = None

        # Remove those blocks from T2, place them in B2
        for block in blocks_t2:
            del self.t2[block]
            self.b2[block] = None

        # Remove file from file2blocks mapping
        if file in self.file2blocks:
            del self.file2blocks[file]

        # Indicate that the file is no longer in SSD
        self.file2tier[file] = 0

    def remove_all_hard(self, file: File):
        """
        Force remove all blocks of the given file from T1, T2, B1, and B2.
        Also removes the file from the SSD tier physically.

        :param file: The File object to remove completely.
        """
        if file in self.file2blocks:
            blocks = self.file2blocks[file]
            for block in blocks:
                self.t1.pop(block, None)
                self.t2.pop(block, None)
                self.b1.pop(block, None)
                self.b2.pop(block, None)
            del self.file2blocks[file]

        # Indicate that the file is no longer in SSD
        self.file2tier[file] = 0

        # Physically remove the file from the SSD tier
        self.ssd_tier.remove_file(file.name)

    def log_user_times(self):
        """
        Log each user's IOPS, throughput, and other usage stats in the log file,
        along with eviction miss percentage.
        """
        user_throughputs = self.calculate_user_throughput()

        # Calculate eviction miss percentage
        eviction_miss_percentage = (self.eviction_misses / self.misses) * 100 if self.misses > 0 else 0

        # Open the log file in append mode
        with open(self.log_file_path, 'a') as log_file:
            log_file.write(f"Time updated at: {datetime.datetime.now()}\n")
            log_file.write(f"Eviction Miss Percentage: {eviction_miss_percentage:.2f}%\n")

            # For each user, log usage and performance stats
            for user_id in self.users:
                time_spent = self.users[user_id].time_spent
                throughput = (
                    self.user_request_sizes[user_id] / self.user_total_time[user_id]
                ) if self.user_total_time[user_id] > 0 else 0
                iops = (
                    self.user_requests[user_id] / self.user_total_time[user_id]
                ) if self.user_total_time[user_id] > 0 else 0
                space_default = self.users[user_id].space_default
                space_used = self.users[user_id].space_utilization

                log_file.write(
                    f"User {user_id}: IOPS = {iops:.2f} ops/sec | "
                    f"Throughput = {throughput} bytes/sec | "
                    f"Total Time = {time_spent} s | "
                    f"Default Space = {space_default} | "
                    f"Used Space = {space_used}\n"
                )
            log_file.write("\n")

    def load_file_to(self, file, tier):
        """
        Load (move) a file to the specified tier.
        Ensures there is space in the cache, evicting files if needed,
        and adds all of the file's blocks to the given tier structure.

        :param file: The File object to load into the tier.
        :param tier: The tier (t1 or t2) to which the file is loaded.
        """
        # Evict until there is enough space to load this file
        while file.size > (self.c - (len(self.t1) + len(self.t2))):
            self.evict()

        # Add each block of the file to the provided tier
        for block_offset in range(file.size):
            block = (file, block_offset)
            self.file2blocks[file].add(block)
            tier[block] = None

        # Mark that the file is now in SSD
        self.ssd_tier.add_file(file)
        self.file2tier[file] = 1

        # Increase the user's SSD space usage
        self.users[file.user_id].increase_space(file.size)

        # Track that this file is in the SSD set
        self.files_in_ssd.add(file)

    def move_file_to(self, file, tier):
        """
        Move a file from SSD to another tier or force reloading in the same tier structure
        (SSD -> remove_all_hard -> load_file_to).

        :param file: The File object to move.
        :param tier: The tier (T1 or T2) to which the file is moved.
        """
        # First remove all blocks from SSD completely
        self.remove_all_hard(file)

        # Then load file to the specified tier
        self.load_file_to(file, tier)

    def is_filename_in_b1(self, file_name):
        """
        Check if a file name is in the B1 ghost list.

        :param file_name: The name of the file to check.
        :return: True if the file name is in B1, False otherwise.
        """
        return any(file_obj.name == file_name for file_obj, _ in self.b1.keys())

    def is_filename_in_b2(self, file_name):
        """
        Check if a file name is in the B2 ghost list.

        :param file_name: The name of the file to check.
        :return: True if the file name is in B2, False otherwise.
        """
        return any(file_obj.name == file_name for file_obj, _ in self.b2.keys())

    def is_filename_in_t2(self, file_name):
        """
        Check if a file name is in T2 (actual SSD data in the second list).

        :param file_name: The name of the file to check.
        :return: True if the file name is in T2, False otherwise.
        """
        return any(file_obj.name == file_name for file_obj, _ in self.t2.keys())

    def is_filename_in_t1(self, file_name):
        """
        Check if a file name is in T1 (actual SSD data in the first list).

        :param file_name: The name of the file to check.
        :return: True if the file name is in T1, False otherwise.
        """
        return any(file_obj.name == file_name for file_obj, _ in self.t1.keys())

    def calculate_user_throughput(self):
        """
        Calculate and return a dictionary of user throughputs (bytes/sec).
        Throughput is defined here as (user_requests[user_id] / user_total_time[user_id])
        * user_request_sizes[user_id], if user_total_time > 0.

        :return: A dictionary mapping user_id to throughput value.
        """
        user_throughputs = {}
        for user_id in self.users:
            if self.user_total_time[user_id] > 0:
                throughput = (
                    (self.user_requests[user_id] / self.user_total_time[user_id]) *
                    self.user_request_sizes[user_id]
                )
                user_throughputs[user_id] = throughput
        return user_throughputs

    def evict(self):
        """
        Evict a file from SSD to HDD (logically).
        The choice of file to evict is based on a combination of position-based score,
        remaining lifetime, and fairness factor (space usage).

        This function updates:
        - self.evicted_files (the set of evicted files)
        - the file's tier membership
        - usage counters, and triggers removal from T1/T2
        - potential removal from ghost lists
        """
        # file2position_score: score based on position in T1 and T2
        file2position_score = defaultdict(float)

        # file2lifetime_score: score based on remaining lifetime
        file2lifetime_score = defaultdict(float)

        # file2fairness_score: score based on user space usage
        file2fairness_score = defaultdict(float)

        # Compute position scores (the further in T1/T2, the higher the score)
        for i, block in enumerate(self.t1):
            file, _ = block
            file2position_score[file] += (len(self.t1) - (i + 1))

        for j, block in enumerate(self.t2):
            file, _ = block
            file2position_score[file] += (len(self.t2) - (j + 1))

        # Normalize by file size
        for file in file2position_score.keys():
            file2position_score[file] /= file.size

        # Compute lifetime scores
        for file in set(file2position_score.keys()):
            remaining_lifetime = file.lifetime - (self.time_now - file.firstAccessTime)
            if remaining_lifetime <= 0:
                file2lifetime_score[file] = 1e6
            else:
                time_diff = remaining_lifetime / 1000
                file2lifetime_score[file] = np.exp(-np.float64(time_diff))

        # Compute fairness scores
        for file in set(file2position_score.keys()):
            if self.users[file.user_id].space_default != 0:
                file2fairness_score[file] = np.float64(
                    (self.users[file.user_id].space_utilization - self.users[file.user_id].space_default) /
                    self.users[file.user_id].space_default
                ) if self.users[file.user_id].space_default <= \
                     self.users[file.user_id].space_utilization else 0

        max_position_score = max(file2position_score.values())
        max_lifetime_score = max(file2lifetime_score.values(), default=1)
        max_fairness_score = max(file2fairness_score.values(), default=1)

        combined_scores = {}

        # Combine normalized scores
        for f in file2position_score:
            norm_pos = file2position_score[f] / max_position_score if max_position_score != 0 else 0
            norm_life = file2lifetime_score[f] / max_lifetime_score if max_lifetime_score != 0 else 0
            norm_fair = file2fairness_score[f] / max_fairness_score if max_fairness_score != 0 else 0
            combined_scores[f] = (norm_pos + norm_life + norm_fair) / 3.0

        # Select the file with the highest combined score
        worse_file = max(combined_scores, key=combined_scores.get, default=None)

        # Mark the file as evicted
        self.evicted_files.add(worse_file)

        # Decrease the user's SSD space usage
        self.users[worse_file.user_id].decrease_space(worse_file.size)

        # Remove the file from the SSD tier
        self.ssd_tier.remove_file(worse_file.name)

        # Add file to the HDD tier
        self.hdd_tier.add_file(worse_file)

        # Update counters
        self.evicted_blocks_count += worse_file.size
        self.evicted_file_count += 1

        # Remove the file blocks from T1/T2, put them in B1/B2
        self.remove_all(worse_file)

        # Keep track of files evicted during this request
        if not hasattr(self, 'evicted_files_during_request'):
            self.evicted_files_during_request = []
        self.evicted_files_during_request.append(worse_file)

        # Manage B1 and B2 ghost lists if needed
        if (len(self.t1) + len(self.b1)) == self.c:
            if len(self.t1) < self.c:
                if len(self.b1) >= worse_file.size:
                    for _ in range(worse_file.size):
                        oldest_key2 = next(iter(self.b1))
                        self.b1.pop(oldest_key2)
                else:
                    if len(self.b1) >= self.adapte_B1:
                        for _ in range(self.adapte_B1):
                            oldest_key = next(iter(self.b1))
                            self.b1.pop(oldest_key)
                    else:
                        nombre_blocs_supprimes_b1 = len(self.b1)
                        self.b1.clear()
                        for _ in range(worse_file.size - nombre_blocs_supprimes_b1):
                            oldest_key2 = next(iter(self.b2))
                            self.b2.pop(oldest_key2)
                    if len(self.b2) >= self.adapte_B2:
                        for _ in range(self.adapte_B2):
                            oldest_key2 = next(iter(self.b2))
                            self.b2.pop(oldest_key2)
                    else:
                        nombre_blocs_supprimes_b2 = len(self.b2)
                        self.b2.clear()
                        for _ in range(worse_file.size - nombre_blocs_supprimes_b2):
                            oldest_key2 = next(iter(self.b1))
                            self.b1.pop(oldest_key2)
        elif (len(self.t1) + len(self.t2) + len(self.b1) + len(self.b2)) >= self.c:
            if (len(self.t1) + len(self.t2) + len(self.b1) + len(self.b2)) == (self.c * 2):
                if len(self.b2) >= worse_file.size:
                    for _ in range(worse_file.size):
                        oldest_key2 = next(iter(self.b2))
                        self.b2.pop(oldest_key2)
                else:
                    if len(self.b2) >= self.adapte_B2:
                        for _ in range(self.adapte_B2):
                            oldest_key2 = next(iter(self.b2))
                            self.b2.pop(oldest_key2)
                    else:
                        nombre_blocs_supprimes_b2 = len(self.b2)
                        self.b2.clear()
                        for _ in range(worse_file.size - nombre_blocs_supprimes_b2):
                            oldest_key2 = next(iter(self.b1))
                            self.b1.pop(oldest_key2)
                    if len(self.b1) >= self.adapte_B1:
                        for _ in range(self.adapte_B1):
                            oldest_key = next(iter(self.b1))
                            self.b1.pop(oldest_key)
                    else:
                        nombre_blocs_supprimes_b1 = len(self.b1)
                        self.b1.clear()
                        for _ in range(worse_file.size - nombre_blocs_supprimes_b1):
                            oldest_key2 = next(iter(self.b2))
                            self.b2.pop(oldest_key2)

    def _transfer_data_with_burst(self, data_size, read_tier=None, write_tier=None):
        """
        Utility function to transfer data_size bytes using a burst buffer
        between read_tier and write_tier.

        :param data_size: The total number of bytes to transfer.
        :param read_tier: The tier from which data is read.
        :param write_tier: The tier to which data is written.
        :return: (read_time, write_time)
        """
        read_time = 0.0
        write_time = 0.0

        # If we are reading data from a tier
        if read_tier:
            remaining = data_size
            while remaining > 0:
                # We take a burst of data up to the burst_buffer_size
                burst = max(remaining, self.burst_buffer_size)
                read_time += (burst / read_tier.read_throughput) + read_tier.latency
                remaining -= burst

        # If we are writing data to a tier
        if write_tier:
            remaining = data_size
            while remaining > 0:
                burst = max(remaining, self.burst_buffer_size)
                write_time += (burst / write_tier.write_throughput) + write_tier.latency
                remaining -= burst

        return read_time, write_time

    def on_io(self, file, timestamp, requestType, offsetStart, offsetEnd):
        """
        Handle an IO operation on the given file from offsetStart to offsetEnd at the specified timestamp.
        This function processes hits/misses, evictions, and possible block movements between HDD and SSD.

        :param file: The File object being accessed.
        :param timestamp: The timestamp of the IO operation.
        :param requestType: The type of request (read/write).
        :param offsetStart: The starting block offset.
        :param offsetEnd: The ending block offset (non-inclusive).
        """

        # We reset the list of evictions for this request
        self.evicted_files_during_request = []

        # Reset time counters for this IO
        self.total_time = 0
        self.ssd_time = 0
        self.hdd_time = 0

        # Update current time
        self.time_now = timestamp
        self.timestamp = timestamp

        # Assume this is not a new file unless proven otherwise
        self.new_file = False

        # Increment the number of IO operations processed so far
        self.io_counter += 1

        # Identify user
        user_id = file.user_id

        # Calculate request size in blocks and in bytes
        request_size_in_blocks = (offsetEnd - offsetStart)
        request_size_in_bytes = request_size_in_blocks * self.block_size

        # Update user metrics
        self.user_request_sizes[user_id] += request_size_in_bytes
        self.user_requests[user_id] += 1

        # Track whether we have recorded if this miss is an eviction miss or cold miss
        miss_type_recorded = False

        # If the file was previously evicted from SSD, log its reloading
        if file in self.evicted_files_SSD:
            with open(self.eviction_log_file, 'a') as log_file:
                log_file.write(f"Reloading evicted file into SSD: {file.name}\n")
                log_file.write(f"Timestamp: {timestamp}\n")
                log_file.write('--------------------------------------------\n')

        # Iterate over each block of the request
        for block_offset in range(offsetStart, offsetEnd):
            block = (file, block_offset)

            # Check if block is a hit (in T1 or T2) or a miss
            if (block in self.t1 and not self.new_file) or (block in self.t2):
                self.hits += 1
            else:
                self.misses += 1
                if not miss_type_recorded:
                    if file in self.evicted_files:
                        self.eviction_misses += 1
                    elif file not in self.files_in_ssd:
                        self.cold_misses += 1
                    miss_type_recorded = True

            # If block is in T1 (SSD), read time is immediate for SSD
            if block in self.t1:
                if not self.new_file:
                    # Move block from T1 to T2 upon access
                    self.ssd_time += (self.block_size / self.ssd_tier.read_throughput) + self.ssd_tier.latency
                    del self.t1[block]
                    self.t2[block] = None
                else:
                    # If it's a new file, still read from SSD
                    self.ssd_time += (self.block_size / self.ssd_tier.read_throughput) + self.ssd_tier.latency

            elif block in self.t2:
                # The block is in T2, read from SSD
                self.ssd_time += (self.block_size / self.ssd_tier.read_throughput) + self.ssd_tier.latency

                # Refresh the block in T2
                del self.t2[block]
                self.t2[block] = None

            elif block in self.b1:
                # If the block is in the B1 ghost list, adapt p
                self.p = min(self.p + max(round(len(self.b2) / (len(self.b1))), file.size), self.c)

                # Move file to T2
                self.move_file_to(file, self.t2)

                # Remove the file from HDD tier
                self.hdd_tier.remove_file(file.name)

                # Immediate HDD->SSD transfer for the entire file
                data_size_file = file.size * self.block_size
                hdd_read, ssd_write = self._transfer_data_with_burst(data_size_file, self.hdd_tier, self.ssd_tier)
                self.hdd_time += hdd_read
                self.ssd_time += ssd_write

            elif block in self.b2:
                # If the block is in the B2 ghost list, adapt p
                self.p = max(self.p - max(round(len(self.b1) / (len(self.b2))), file.size), 0)

                # Move file to T2
                self.move_file_to(file, self.t2)

                # Remove the file from HDD tier
                self.hdd_tier.remove_file(file.name)

                # Immediate HDD->SSD transfer
                data_size_file = file.size * self.block_size
                hdd_read, ssd_write = self._transfer_data_with_burst(data_size_file, self.hdd_tier, self.ssd_tier)
                self.hdd_time += hdd_read
                self.ssd_time += ssd_write

            elif self.hdd_tier.is_file_in_tier(file.name) and not self.is_filename_in_b1(file.name) and not self.is_filename_in_b2(file.name):
                # If the file is on HDD but not in B1 or B2
                if file.size <= self.c:
                    # If the file can fit in SSD
                    self.new_file = True
                    self.hdd_tier.remove_file(file.name)
                    self.remove_all_hard(file)
                    self.load_file_to(file, self.t1)
                    self.file2tier[file] = 1

                    # Immediate HDD->SSD transfer
                    data_size_file = file.size * self.block_size
                    hdd_read, ssd_write = self._transfer_data_with_burst(data_size_file, self.hdd_tier, self.ssd_tier)
                    self.hdd_time += hdd_read
                    self.ssd_time += ssd_write
                else:
                    # The file is too big for SSD, read the block from HDD
                    hdd_read = (self.block_size / self.hdd_tier.read_throughput)
                    self.hdd_time += hdd_read
                    self.nbr_of_blocks_hdd_reads += 1

            else:
                # If the file is not in HDD or SSD, it must be a new file (not stored anywhere yet)
                if not self.hdd_tier.is_file_in_tier(file.name) and not self.ssd_tier.is_file_in_tier(file.name):
                    if file.size <= self.c:
                        # If file can fit in SSD
                        self.new_file = True
                        self.load_file_to(file, self.t1)
                        self.file2tier[file] = 1

                        # Immediate SSD write for the block
                        data_size_file = self.block_size
                        ssd_write = (data_size_file / self.ssd_tier.write_throughput)
                        self.ssd_time += ssd_write
                    else:
                        # Otherwise, treat as an HDD read for the block
                        self.hdd_tier.add_file(file)
                        hdd_read = (self.block_size / self.hdd_tier.read_throughput) + self.hdd_tier.latency
                        self.hdd_time += hdd_read
                        self.nbr_of_blocks_hdd_reads += 1

        # After processing all blocks, handle the SSD->HDD evictions
        # that happened during this IO in one burst transfer
        if hasattr(self, 'evicted_files_during_request') and self.evicted_files_during_request:
            total_data_size = sum(f.size for f in self.evicted_files_during_request) * self.block_size
            ssd_read_time, hdd_write_time = self._transfer_data_with_burst(total_data_size, self.ssd_tier, self.hdd_tier)
            self.ssd_time += ssd_read_time
            self.hdd_time += hdd_write_time

        # Calculate total time spent on this IO operation
        self.total_time += self.ssd_time + self.hdd_time

        # Update user total time
        self.user_total_time[file.user_id] += self.total_time

        # Update time spent for the user object
        self.users[file.user_id].increase_time_spent(self.total_time)

        # Debug print for verifying the IO counter
        print(self.io_counter)

        # If this IO is the last one, log user times
        if self.io_counter == self.total_io_operations:
            print("f It's the last file")
            self.log_user_times()
            self.io_counter = 0
